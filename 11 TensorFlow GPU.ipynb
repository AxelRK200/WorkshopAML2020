{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow GPU avec Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/retkowsky/images/blob/master/AzureMLservicebanniere.png?raw=true'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) \\n[GCC 7.3.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date du run =  2020-02-25 14:39:19.876194\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "maintenant = datetime.datetime.now()\n",
    "print(\"Date du run = \", maintenant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Azure ML =  1.0.83\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"Version Azure ML = \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code CT4Z5KWFF to authenticate.\n",
      "Interactive authentication successfully completed.\n",
      "Workspace name: workshop-aml-2020\n",
      "Azure region: westeurope\n",
      "Subscription id: 70b8f39e-8863-49f7-b6ba-34a80799550c\n",
      "Resource group: workshopaml2020RG\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. AML Compute GPU\n",
    "\n",
    "Les tailles NC, NCv2 et NCv3 sont optimisées pour les algorithmes et les applications nécessitant beaucoup de ressources réseau et de calculs. \n",
    "\n",
    "En voici quelques exemples : les applications et les simulations CUDA et OpenCL, l’intelligence artificielle et l’apprentissage profond. Équipée du GPU Tesla V100 de NVIDIA, la série NCv3 est axée sur les charges de travail informatiques à hautes performances. \n",
    "\n",
    "- La série NC utilise le processeur Intel Xeon E5-2690 v3 2.60GHz v3 (Haswell) et les machines virtuelles de la série NCv2 et NCv3 sont dotées du processeur Intel Xeon E5-2690 v4 (Broadwell).\n",
    "\n",
    "- ND et NDv2La série ND est destinée à l’exécution de scénarios d’apprentissage et d’inférence pour le Deep Learning. Elle utilise le GPU NVIDIA Tesla P40 et le processeur Intel Xeon E5-2690 v4 (Broadwell). La série NDv2 utilise le processeur Intel Xeon Platinum 8168 (Skylake).\n",
    "\n",
    "- Les tailles NV et NVv3 sont optimisées et conçues pour la visualisation à distance, la diffusion en continu, les jeux, l’encodage et les scénarios de VDI utilisant des infrastructures comme OpenGL ou DirectX. Ces machines virtuelles reposent sur le GPU Tesla M60 de NVIDIA.\n",
    "\n",
    "- Les tailles NVv4 sont optimisées et conçues pour l’infrastructure VDI et la visualisation à distance. Avec des GPU partitionnés, NVv4 offre la taille adaptée aux charges de travail nécessitant des ressources GPU plus petites. Ces machines virtuelles sont associées au GPU AMD Radeon Instinct MI25.\n",
    "\n",
    "https://docs.microsoft.com/fr-fr/azure/virtual-machines/windows/sizes-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Standard_D1_v2',\n",
       "  'vCPUs': 1,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3.5,\n",
       "  'maxResourceVolumeMB': 51200},\n",
       " {'name': 'Standard_D2_v2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 7.0,\n",
       "  'maxResourceVolumeMB': 102400},\n",
       " {'name': 'Standard_D3_v2',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 204800},\n",
       " {'name': 'Standard_D4_v2',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 409600},\n",
       " {'name': 'Standard_D11_v2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 102400},\n",
       " {'name': 'Standard_D12_v2',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 204800},\n",
       " {'name': 'Standard_D13_v2',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 56.0,\n",
       "  'maxResourceVolumeMB': 409600},\n",
       " {'name': 'Standard_D14_v2',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 819200},\n",
       " {'name': 'Standard_DS1_v2',\n",
       "  'vCPUs': 1,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3.5,\n",
       "  'maxResourceVolumeMB': 7168},\n",
       " {'name': 'Standard_DS2_v2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 7.0,\n",
       "  'maxResourceVolumeMB': 14336},\n",
       " {'name': 'Standard_DS3_v2',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 28672},\n",
       " {'name': 'Standard_DS4_v2',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 57344},\n",
       " {'name': 'Standard_DS5_v2',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 56.0,\n",
       "  'maxResourceVolumeMB': 114688},\n",
       " {'name': 'Standard_DS11_v2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 28672},\n",
       " {'name': 'Standard_DS12_v2',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 57344},\n",
       " {'name': 'Standard_DS13_v2',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 56.0,\n",
       "  'maxResourceVolumeMB': 114688},\n",
       " {'name': 'Standard_DS14_v2',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 229376},\n",
       " {'name': 'Standard_M8-2ms',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 218.75,\n",
       "  'maxResourceVolumeMB': 256000},\n",
       " {'name': 'Standard_M8-4ms',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 218.75,\n",
       "  'maxResourceVolumeMB': 256000},\n",
       " {'name': 'Standard_M8ms',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 218.75,\n",
       "  'maxResourceVolumeMB': 256000},\n",
       " {'name': 'Standard_M16-4ms',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 437.5,\n",
       "  'maxResourceVolumeMB': 512000},\n",
       " {'name': 'Standard_M16-8ms',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 437.5,\n",
       "  'maxResourceVolumeMB': 512000},\n",
       " {'name': 'Standard_M16ms',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 437.5,\n",
       "  'maxResourceVolumeMB': 512000},\n",
       " {'name': 'Standard_M32-8ms',\n",
       "  'vCPUs': 32,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 875.0,\n",
       "  'maxResourceVolumeMB': 1024000},\n",
       " {'name': 'Standard_M32-16ms',\n",
       "  'vCPUs': 32,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 875.0,\n",
       "  'maxResourceVolumeMB': 1024000},\n",
       " {'name': 'Standard_M32ls',\n",
       "  'vCPUs': 32,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 256.0,\n",
       "  'maxResourceVolumeMB': 1024000},\n",
       " {'name': 'Standard_M32ms',\n",
       "  'vCPUs': 32,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 875.0,\n",
       "  'maxResourceVolumeMB': 1024000},\n",
       " {'name': 'Standard_M32ts',\n",
       "  'vCPUs': 32,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 192.0,\n",
       "  'maxResourceVolumeMB': 1024000},\n",
       " {'name': 'Standard_M64-16ms',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 1750.0,\n",
       "  'maxResourceVolumeMB': 2048000},\n",
       " {'name': 'Standard_M64-32ms',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 1750.0,\n",
       "  'maxResourceVolumeMB': 2048000},\n",
       " {'name': 'Standard_M64ls',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 512.0,\n",
       "  'maxResourceVolumeMB': 2048000},\n",
       " {'name': 'Standard_M64ms',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 1750.0,\n",
       "  'maxResourceVolumeMB': 2048000},\n",
       " {'name': 'Standard_M64s',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 1000.0,\n",
       "  'maxResourceVolumeMB': 2048000},\n",
       " {'name': 'Standard_M128-32ms',\n",
       "  'vCPUs': 128,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3800.0,\n",
       "  'maxResourceVolumeMB': 4096000},\n",
       " {'name': 'Standard_M128-64ms',\n",
       "  'vCPUs': 128,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3800.0,\n",
       "  'maxResourceVolumeMB': 4096000},\n",
       " {'name': 'Standard_M128ms',\n",
       "  'vCPUs': 128,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3800.0,\n",
       "  'maxResourceVolumeMB': 4096000},\n",
       " {'name': 'Standard_M128s',\n",
       "  'vCPUs': 128,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 2000.0,\n",
       "  'maxResourceVolumeMB': 4096000},\n",
       " {'name': 'Standard_M64',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 1000.0,\n",
       "  'maxResourceVolumeMB': 8192000},\n",
       " {'name': 'Standard_M64m',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 1750.0,\n",
       "  'maxResourceVolumeMB': 8192000},\n",
       " {'name': 'Standard_M128',\n",
       "  'vCPUs': 128,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 2000.0,\n",
       "  'maxResourceVolumeMB': 16384000},\n",
       " {'name': 'Standard_M128m',\n",
       "  'vCPUs': 128,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3800.0,\n",
       "  'maxResourceVolumeMB': 16384000},\n",
       " {'name': 'Standard_D1',\n",
       "  'vCPUs': 1,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3.5,\n",
       "  'maxResourceVolumeMB': 51200},\n",
       " {'name': 'Standard_D2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 7.0,\n",
       "  'maxResourceVolumeMB': 102400},\n",
       " {'name': 'Standard_D3',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 204800},\n",
       " {'name': 'Standard_D4',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 409600},\n",
       " {'name': 'Standard_D11',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 102400},\n",
       " {'name': 'Standard_D12',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 204800},\n",
       " {'name': 'Standard_D13',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 56.0,\n",
       "  'maxResourceVolumeMB': 409600},\n",
       " {'name': 'Standard_D14',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 819200},\n",
       " {'name': 'Standard_DS15_v2',\n",
       "  'vCPUs': 20,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 140.0,\n",
       "  'maxResourceVolumeMB': 286720},\n",
       " {'name': 'Standard_NV6',\n",
       "  'vCPUs': 6,\n",
       "  'gpus': 1,\n",
       "  'memoryGB': 56.0,\n",
       "  'maxResourceVolumeMB': 389120},\n",
       " {'name': 'Standard_NV12',\n",
       "  'vCPUs': 12,\n",
       "  'gpus': 2,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 696320},\n",
       " {'name': 'Standard_NV24',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 224.0,\n",
       "  'maxResourceVolumeMB': 1474560},\n",
       " {'name': 'Standard_F2s_v2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 4.0,\n",
       "  'maxResourceVolumeMB': 16384},\n",
       " {'name': 'Standard_F4s_v2',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 8.0,\n",
       "  'maxResourceVolumeMB': 32768},\n",
       " {'name': 'Standard_F8s_v2',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 16.0,\n",
       "  'maxResourceVolumeMB': 65536},\n",
       " {'name': 'Standard_F16s_v2',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 32.0,\n",
       "  'maxResourceVolumeMB': 131072},\n",
       " {'name': 'Standard_F32s_v2',\n",
       "  'vCPUs': 32,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 64.0,\n",
       "  'maxResourceVolumeMB': 262144},\n",
       " {'name': 'Standard_F64s_v2',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 128.0,\n",
       "  'maxResourceVolumeMB': 524288},\n",
       " {'name': 'Standard_F72s_v2',\n",
       "  'vCPUs': 72,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 144.0,\n",
       "  'maxResourceVolumeMB': 589824},\n",
       " {'name': 'Standard_NC6s_v3',\n",
       "  'vCPUs': 6,\n",
       "  'gpus': 1,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 344064},\n",
       " {'name': 'Standard_NC12s_v3',\n",
       "  'vCPUs': 12,\n",
       "  'gpus': 2,\n",
       "  'memoryGB': 224.0,\n",
       "  'maxResourceVolumeMB': 688128},\n",
       " {'name': 'Standard_NC24rs_v3',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 448.0,\n",
       "  'maxResourceVolumeMB': 1376256},\n",
       " {'name': 'Standard_NC24s_v3',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 448.0,\n",
       "  'maxResourceVolumeMB': 1376256},\n",
       " {'name': 'Standard_NC6',\n",
       "  'vCPUs': 6,\n",
       "  'gpus': 1,\n",
       "  'memoryGB': 56.0,\n",
       "  'maxResourceVolumeMB': 389120},\n",
       " {'name': 'Standard_NC12',\n",
       "  'vCPUs': 12,\n",
       "  'gpus': 2,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 696320},\n",
       " {'name': 'Standard_NC24',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 224.0,\n",
       "  'maxResourceVolumeMB': 1474560},\n",
       " {'name': 'Standard_NC24r',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 224.0,\n",
       "  'maxResourceVolumeMB': 1474560},\n",
       " {'name': 'Standard_ND6s',\n",
       "  'vCPUs': 6,\n",
       "  'gpus': 1,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 344064},\n",
       " {'name': 'Standard_ND12s',\n",
       "  'vCPUs': 12,\n",
       "  'gpus': 2,\n",
       "  'memoryGB': 224.0,\n",
       "  'maxResourceVolumeMB': 688128},\n",
       " {'name': 'Standard_ND24rs',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 448.0,\n",
       "  'maxResourceVolumeMB': 1376256},\n",
       " {'name': 'Standard_ND24s',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 448.0,\n",
       "  'maxResourceVolumeMB': 1376256},\n",
       " {'name': 'Standard_NC6s_v2',\n",
       "  'vCPUs': 6,\n",
       "  'gpus': 1,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 344064},\n",
       " {'name': 'Standard_NC12s_v2',\n",
       "  'vCPUs': 12,\n",
       "  'gpus': 2,\n",
       "  'memoryGB': 224.0,\n",
       "  'maxResourceVolumeMB': 688128},\n",
       " {'name': 'Standard_NC24rs_v2',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 448.0,\n",
       "  'maxResourceVolumeMB': 1376256},\n",
       " {'name': 'Standard_NC24s_v2',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 448.0,\n",
       "  'maxResourceVolumeMB': 1376256},\n",
       " {'name': 'Standard_ND40rs_v2',\n",
       "  'vCPUs': 40,\n",
       "  'gpus': 8,\n",
       "  'memoryGB': 672.0,\n",
       "  'maxResourceVolumeMB': 2969600},\n",
       " {'name': 'Standard_NV12s_v3',\n",
       "  'vCPUs': 12,\n",
       "  'gpus': 1,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 344064},\n",
       " {'name': 'Standard_NV24s_v3',\n",
       "  'vCPUs': 24,\n",
       "  'gpus': 2,\n",
       "  'memoryGB': 224.0,\n",
       "  'maxResourceVolumeMB': 688128},\n",
       " {'name': 'Standard_NV48s_v3',\n",
       "  'vCPUs': 48,\n",
       "  'gpus': 4,\n",
       "  'memoryGB': 448.0,\n",
       "  'maxResourceVolumeMB': 1376256}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "AmlCompute.supported_vmsizes(workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2020-02-25T14:32:58.036000+00:00', 'errors': None, 'creationTime': '2020-02-14T09:06:06.484277+00:00', 'modifiedTime': '2020-02-14T09:06:21.946369+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpu-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AKSML\n",
      "my-aks-test4\n",
      "automl2\n",
      "cpu-cluster\n",
      "pipeline\n",
      "gpu-cluster\n",
      "gpu-cluster2\n",
      "gpucluster\n",
      "train-many-model\n"
     ]
    }
   ],
   "source": [
    "cts = ws.compute_targets\n",
    "for ct in cts:\n",
    "    print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "web_paths = ['http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "             'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "             'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "             'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
    "            ]\n",
    "dataset = Dataset.File.from_files(path = web_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.register(workspace = ws,\n",
    "                           name = 'mnist dataset',\n",
    "                           description='training and test dataset',\n",
    "                           create_new_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/http/yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
       "       '/http/yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
       "       '/http/yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
       "       '/http/yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Création projet et expérimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './tf-resume-training'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'Workshop11-TensorFlow'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Création et exécution estimator TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation du code python :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
      "# Licensed under the MIT License.\n",
      "\n",
      "import numpy as np\n",
      "import utils\n",
      "import argparse\n",
      "import os\n",
      "import re\n",
      "import tensorflow as tf\n",
      "import glob\n",
      "\n",
      "from azureml.core import Run\n",
      "from utils import load_data\n",
      "\n",
      "print(\"TensorFlow version:\", tf.__version__)\n",
      "\n",
      "parser = argparse.ArgumentParser()\n",
      "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
      "\n",
      "parser.add_argument('--resume-from', type=str, default=None,\n",
      "                    help='location of the model or checkpoint files from where to resume the training')\n",
      "args = parser.parse_args()\n",
      "\n",
      "\n",
      "previous_model_location = args.resume_from\n",
      "# You can also use environment variable to get the model/checkpoint files location\n",
      "# previous_model_location = os.path.expandvars(os.getenv(\"AZUREML_DATAREFERENCE_MODEL_LOCATION\", None))\n",
      "\n",
      "data_folder = args.data_folder\n",
      "print('Data folder:', data_folder)\n",
      "\n",
      "# load train and test set into numpy arrays\n",
      "# note we scale the pixel intensity values to 0-1 (by dividing it with 255.0) so the model can converge faster.\n",
      "\n",
      "X_train = load_data(glob.glob(os.path.join(data_folder, '**/train-images-idx3-ubyte.gz'),\n",
      "                              recursive=True)[0], False) / 255.0\n",
      "X_test = load_data(glob.glob(os.path.join(data_folder, '**/t10k-images-idx3-ubyte.gz'),\n",
      "                             recursive=True)[0], False) / 255.0\n",
      "y_train = load_data(glob.glob(os.path.join(data_folder, '**/train-labels-idx1-ubyte.gz'),\n",
      "                              recursive=True)[0], True).reshape(-1)\n",
      "y_test = load_data(glob.glob(os.path.join(data_folder, '**/t10k-labels-idx1-ubyte.gz'),\n",
      "                             recursive=True)[0], True).reshape(-1)\n",
      "\n",
      "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep='\\n')\n",
      "\n",
      "training_set_size = X_train.shape[0]\n",
      "\n",
      "n_inputs = 28 * 28\n",
      "n_h1 = 100\n",
      "n_h2 = 100\n",
      "n_outputs = 10\n",
      "learning_rate = 0.01\n",
      "n_epochs = 20\n",
      "batch_size = 50\n",
      "\n",
      "with tf.name_scope('network'):\n",
      "    # construct the DNN\n",
      "    X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
      "    y = tf.placeholder(tf.int64, shape=(None), name='y')\n",
      "    h1 = tf.layers.dense(X, n_h1, activation=tf.nn.relu, name='h1')\n",
      "    h2 = tf.layers.dense(h1, n_h2, activation=tf.nn.relu, name='h2')\n",
      "    output = tf.layers.dense(h2, n_outputs, name='output')\n",
      "\n",
      "with tf.name_scope('train'):\n",
      "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=output)\n",
      "    loss = tf.reduce_mean(cross_entropy, name='loss')\n",
      "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
      "    train_op = optimizer.minimize(loss)\n",
      "\n",
      "with tf.name_scope('eval'):\n",
      "    correct = tf.nn.in_top_k(output, y, 1)\n",
      "    acc_op = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
      "\n",
      "init = tf.global_variables_initializer()\n",
      "saver = tf.train.Saver()\n",
      "\n",
      "# start an Azure ML run\n",
      "run = Run.get_context()\n",
      "\n",
      "with tf.Session() as sess:\n",
      "    start_epoch = 0\n",
      "    if previous_model_location:\n",
      "        checkpoint_file_path = tf.train.latest_checkpoint(previous_model_location)\n",
      "        saver.restore(sess, checkpoint_file_path)\n",
      "        checkpoint_filename = os.path.basename(checkpoint_file_path)\n",
      "        num_found = re.search(r'\\d+', checkpoint_filename)\n",
      "        if num_found:\n",
      "            start_epoch = int(num_found.group(0))\n",
      "            print(\"Resuming from epoch {}\".format(str(start_epoch)))\n",
      "    else:\n",
      "        init.run()\n",
      "\n",
      "    for epoch in range(start_epoch, n_epochs):\n",
      "\n",
      "        # randomly shuffle training set\n",
      "        indices = np.random.permutation(training_set_size)\n",
      "        X_train = X_train[indices]\n",
      "        y_train = y_train[indices]\n",
      "\n",
      "        # batch index\n",
      "        b_start = 0\n",
      "        b_end = b_start + batch_size\n",
      "        for _ in range(training_set_size // batch_size):\n",
      "            # get a batch\n",
      "            X_batch, y_batch = X_train[b_start: b_end], y_train[b_start: b_end]\n",
      "\n",
      "            # update batch index for the next batch\n",
      "            b_start = b_start + batch_size\n",
      "            b_end = min(b_start + batch_size, training_set_size)\n",
      "\n",
      "            # train\n",
      "            sess.run(train_op, feed_dict={X: X_batch, y: y_batch})\n",
      "        # evaluate training set\n",
      "        acc_train = acc_op.eval(feed_dict={X: X_batch, y: y_batch})\n",
      "        # evaluate validation set\n",
      "        acc_val = acc_op.eval(feed_dict={X: X_test, y: y_test})\n",
      "\n",
      "        # log accuracies\n",
      "        run.log('training_acc', np.float(acc_train))\n",
      "        run.log('validation_acc', np.float(acc_val))\n",
      "        print(epoch, '-- Training accuracy:', acc_train, '\\b Validation accuracy:', acc_val)\n",
      "        y_hat = np.argmax(output.eval(feed_dict={X: X_test}), axis=1)\n",
      "\n",
      "        if epoch % 5 == 0:\n",
      "            saver.save(sess, './outputs/', global_step=epoch)\n",
      "\n",
      "        # saving only half of the model and resuming again from same epoch\n",
      "        if not previous_model_location and epoch == 10:\n",
      "            break\n",
      "\n",
      "    run.log('final_acc', np.float(acc_val))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(script_folder, './tf_mnist_with_checkpoint.py'), 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - framework_version is not specified, defaulting to version 1.13.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "script_params={\n",
    "    '--data-folder': dataset.as_named_input('mnist').as_mount()\n",
    "}\n",
    "\n",
    "estimator= TensorFlow(source_directory=script_folder,\n",
    "                      compute_target=compute_target,\n",
    "                      script_params=script_params,\n",
    "                      entry_script='tf_mnist_with_checkpoint.py',\n",
    "                      use_gpu=True,\n",
    "                      pip_packages=['azureml-dataprep[pandas,fuse]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exécution du Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Widget pour suivi de l'exécution du run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'Workshop11-TensorFlow_1582642743_60d82eb4',\n",
       " 'target': 'gpu-cluster',\n",
       " 'status': 'Queued',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '56fd9264-43da-4d15-abce-68c8af2a2e32',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': 'fd756227-0649-45fb-8a78-24a6efd10aab'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'mnist', 'mechanism': 'Mount'}}],\n",
       " 'runDefinition': {'script': 'tf_mnist_with_checkpoint.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--data-folder', 'DatasetConsumptionConfig:mnist'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'gpu-cluster',\n",
       "  'dataReferences': {},\n",
       "  'data': {'mnist': {'dataLocation': {'dataset': {'id': 'fd756227-0649-45fb-8a78-24a6efd10aab'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'mnist',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment Workshop11-TensorFlow Environment',\n",
       "   'version': 'Autosave_2020-02-14T09:08:32Z_f8062f18',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-dataprep[pandas,fuse]',\n",
       "        'azureml-defaults',\n",
       "        'tensorflow-gpu==1.13.1',\n",
       "        'horovod==0.16.1']}],\n",
       "     'name': 'azureml_87bf8b18f50c3819153ad5fad9efbcd9'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []}},\n",
       " 'logFiles': {}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métriques (voir aussi dans le Studio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/retkowsky/images/blob/master/Powered-by-MS-Azure-logo-v2.png?raw=true\" height=\"300\" width=\"300\">"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "hesuri"
   }
  ],
  "category": "training",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "MNIST"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "TensorFlow"
  ],
  "friendly_name": "Resuming a model",
  "index_order": 1,
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "msauthor": "hesuri",
  "tags": [
   "None"
  ],
  "task": "Resume a model in TensorFlow from a previously submitted run"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
